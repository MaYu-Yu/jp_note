# import_anki_data.py
import sqlite3
import re
import csv
import os
import sys 
from opencc import OpenCC 

# --- é…ç½®å€ ---
DB_NAME = 'jp_db.db' 

# ğŸš¨ è©æ€§ä»£ç¢¼æ˜ å°„å­—å…¸ (è™•ç† Anki ç´°åˆ†é¡/éæ¨™æº–è©æ€§)
POS_CODE_MAPPER = {
    # ç´°åˆ†é¡çµ±ä¸€åˆ°ä¸»åˆ†é¡
    'è‡ªå‹•1': 'è‡ªå‹•', 
    'è‡ªå‹•2': 'è‡ªå‹•', 
    'è‡ªå‹•3': 'è‡ªå‹•',
    'ä»–å‹•1': 'ä»–å‹•', 
    'ä»–å‹•2': 'ä»–å‹•', 
    'ä»–å‹•3': 'ä»–å‹•',
    
    # éæ¨™æº–æˆ–è¤‡åˆè©çš„çµ±ä¸€è™•ç† (å¦‚æœ Anki æœ‰å‡ºç¾)
    'è£œå‹•': 'å‹•',    # è£œè¶³å‹•è© (ä¾‹å¦‚ï¼šã€œã¦ãã‚Œã‚‹) -> æ­¸é¡ç‚ºå‹•è©
    'å½¢': 'ã„å½¢',   # æ³›æŒ‡å½¢å®¹è© -> æ­¸é¡ç‚º ã„å½¢
    'ä¸': 'Other',   # ä¸è©³
    'è‹±': 'Other',   # è‹±æ–‡
    
    # ç¢ºä¿æ‰€æœ‰ MASTER_POS_LIST ç°¡ç¨±è‡ªå·±æ˜ å°„åˆ°è‡ªå·±
    'å': 'å', 'å°ˆ': 'å°ˆ', 'æ•¸': 'æ•¸', 'ä»£': 'ä»£', 
    'å‹•': 'å‹•', 'è‡ªå‹•': 'è‡ªå‹•', 'ä»–å‹•': 'ä»–å‹•', 
    'ã„å½¢': 'ã„å½¢', 'ãƒŠå½¢': 'ãƒŠå½¢',
    'å‰¯': 'å‰¯', 'é€£ä½“è©': 'é€£ä½“è©', 'æ¥': 'æ¥', 'æ„Ÿ': 'æ„Ÿ', 
    'åŠ©è©': 'åŠ©è©', 'åŠ©å‹•è©': 'åŠ©å‹•è©', 'æ¥å°¾': 'æ¥å°¾', 'æ¥é ­': 'æ¥é ­',
}

# åˆå§‹åŒ– OpenCC è½‰æ›å™¨ (ä¿æŒä¸è®Š)
try:
    s2t = OpenCC('s2t') 
except Exception as e:
    print("OpenCC åˆå§‹åŒ–å¤±æ•—ï¼è«‹ç¢ºèªå·²åŸ·è¡Œ 'pip install opencc-python-reimplementation'ã€‚")
    print(f"éŒ¯èª¤ä¿¡æ¯: {e}")
    # é€™è£¡ä¸ exit(1)ï¼Œä»¥é˜²ç³»çµ±å…è¨±é‹è¡Œï¼Œä½†ç”¨æˆ¶æ²’æœ‰ opencc éœ€æ±‚
    # sys.exit(1)

def get_db_connection():
    """èˆ‡ app.py ç›¸åŒçš„è³‡æ–™åº«é€£ç·šå‡½æ•¸ã€‚"""
    conn = sqlite3.connect(DB_NAME)
    conn.row_factory = sqlite3.Row
    return conn

# ğŸš¨ ä¿®æ­£é»ï¼šé‡æ–°åŠ å…¥ get_or_create_category å‡½æ•¸
def get_or_create_category(conn, category_name):
    """
    æª¢æŸ¥åˆ†é¡æ˜¯å¦å­˜åœ¨ã€‚å¦‚æœä¸å­˜åœ¨ï¼Œå‰‡å‰µå»ºå®ƒä¸¦è¿”å›å…¶ IDã€‚
    """
    cursor = conn.cursor()
    # 1. æª¢æŸ¥åˆ†é¡æ˜¯å¦å·²å­˜åœ¨
    cursor.execute("SELECT id FROM category_table WHERE name = ?", (category_name,))
    row = cursor.fetchone()
    
    if row:
        return row[0]
    
    # 2. å¦‚æœä¸å­˜åœ¨ï¼Œå‰‡å‰µå»ºå®ƒ
    cursor.execute("INSERT INTO category_table (name) VALUES (?)", (category_name,))
    conn.commit()
    return cursor.lastrowid
# --- è½‰æ›å‡½æ•¸ ---
def map_pos_codes(anki_pos_raw):
    """
    å°‡ Anki æª”æ¡ˆä¸­çš„åŸå§‹è©æ€§ï¼ˆåŒ…å«è¤‡åˆè©ï¼‰è½‰æ›ç‚º app.py å¯è­˜åˆ¥çš„æ—¥æ–‡ç°¡ç¨±åˆ—è¡¨ã€‚
    """
    # 1. æ­£è¦åŒ–åˆ†éš”ç¬¦è™Ÿï¼šAnki æª”æ¡ˆå¯èƒ½ä½¿ç”¨ 'ãƒ»', '/', ',', æˆ– ' ' ä¾†åˆ†éš”è¤‡åˆè©æ€§
    anki_pos_raw = anki_pos_raw.replace('ãƒ»', ',').replace('/', ',').replace(' ', ',').strip()
    
    # 2. ä»¥é€—è™Ÿåˆ†éš” Anki åŸå§‹è©æ€§ï¼Œä¸¦å»é™¤ç©ºç™½
    anki_pos_list = [p.strip() for p in anki_pos_raw.split(',') if p.strip()]
    
    final_pos_set = set() # ä½¿ç”¨é›†åˆ (Set) ä¾†è‡ªå‹•å»é™¤é‡è¤‡çš„è©æ€§
    
    for anki_pos in anki_pos_list:
        
        # æŸ¥æ‰¾æ˜ å°„ã€‚å¦‚æœæ‰¾ä¸åˆ°ï¼Œå‰‡ä½¿ç”¨å®ƒè‡ªå·±ä½œç‚ºç°¡ç¨±ã€‚
        mapped_code = POS_CODE_MAPPER.get(anki_pos, anki_pos) 
        
        final_pos_set.add(mapped_code)
            
    # 3. ç¢ºä¿é›†åˆä¸ç‚ºç©ºï¼Œå¦‚æœç‚ºç©ºå‰‡çµ¦äºˆé è¨­å€¼ 'Other'
    if not final_pos_set:
        return 'Other'

    # 4. æ ¹æ“š app.py çš„å‰ç«¯é æœŸæ ¼å¼ï¼Œä»¥ ', ' é€£æ¥ (é€—è™Ÿ+ç©ºæ ¼)
    return ', '.join(sorted(list(final_pos_set))) 


# --- æ ¸å¿ƒåŒ¯å…¥å‡½æ•¸ ---

def import_anki_data(filepath):
    """
    å¾æŒ‡å®šçš„ Anki æª”æ¡ˆåŒ¯å…¥å–®å­—æ•¸æ“šã€‚
    """
    if not os.path.exists(filepath):
        print(f"âŒ æª”æ¡ˆæœªæ‰¾åˆ°ï¼š{filepath}")
        return

    conn = get_db_connection()
    cursor = conn.cursor()

    # 1. æå–ä¸¦å‰µå»ºåˆ†é¡åç¨±
    base_name = os.path.basename(filepath)
    category_name = os.path.splitext(base_name)[0]
    
    if not category_name:
        category_name = "Imported Vocab"

    # ğŸš¨ ä¿®æ­£é»ï¼šèª¿ç”¨ get_or_create_category (ç¾åœ¨å®ƒå·²åœ¨ä¸Šæ–¹å®šç¾©)
    category_id = get_or_create_category(conn, category_name)
    print(f"ä½¿ç”¨çš„åˆ†é¡åç¨±ï¼šã€{category_name}ã€‘ï¼Œåˆ†é¡ IDï¼š{category_id}")
    
    i = 0
    vocab_imported_count = 0
    category_link_count = 0
    
    try:
        # ä½¿ç”¨ 'r' æ¨¡å¼ï¼Œä¸¦æŒ‡å®š utf-8 ç·¨ç¢¼ä¾†è®€å– Anki æª”æ¡ˆ
        with open(filepath, 'r', encoding='utf-8') as f:
            reader = csv.reader(f, delimiter='\t')
            
            # è·³é Anki æ–‡ä»¶çš„é–‹é ­æ¨™è¨˜è¡Œ (å‡è¨­æœ‰å…©è¡Œæ¨™é ­: #separator:tab, #html:false)
            for _ in range(2): 
                try: next(reader) 
                except StopIteration: return

            for i, row in enumerate(reader):
                if not row or len(row) < 15: 
                    continue
                
                # Anki æ¬„ä½ç´¢å¼•: 1=Term, 3=POS, 5=Explanation(SC), 10=Example(Raw)
                term_raw = row[1].strip()       
                pos_raw = row[3].strip()        
                explanation_raw = row[5].strip() 
                example_raw = row[10].strip()    
                
                if not term_raw or not explanation_raw:
                    continue 
                
                # --- æ•¸æ“šæ¸…ç†èˆ‡æ­£è¦åŒ– ---
                
                # 1. åŸ·è¡Œè©æ€§ä»£ç¢¼è½‰æ›
                pos_cleaned = map_pos_codes(pos_raw) 
                
                # 2. ç°¡é«”ä¸­æ–‡è½‰æ›ç‚ºç¹é«”ä¸­æ–‡
                explanation_tc = s2t.convert(explanation_raw)
                
                # 3. æ¸…ç†ä¾‹å¥ (å»é™¤ Anki çš„ç™¼éŸ³æ¨™è¨˜ [ ] )
                example_sentence = re.sub(r'\[.+?\]', '', example_raw).strip()
                term = term_raw
                
                # 1. æ’å…¥åˆ° vocab_table
                cursor.execute("""
                    INSERT INTO vocab_table (term, part_of_speech, explanation, example_sentence)
                    VALUES (?, ?, ?, ?)
                """, (term, pos_cleaned, explanation_tc, example_sentence)) 
                
                vocab_id = cursor.lastrowid 
                vocab_imported_count += 1
                
                # 2. æ’å…¥åˆ° item_category_table (é€£çµåˆ†é¡)
                cursor.execute("""
                    INSERT INTO item_category_table (item_id, category_id, item_type)
                    VALUES (?, ?, ?)
                """, (vocab_id, category_id, 'vocab'))
                category_link_count += 1
                
            conn.commit()
            print("\n----------------------------------------------")
            print(f"âœ… æª”æ¡ˆã€{category_name}ã€‘åŒ¯å…¥æˆåŠŸï¼")
            print(f"   -> åŒ¯å…¥å–®å­—ç¸½æ•¸: {vocab_imported_count} ç­†")
            print(f"   -> é€£çµåˆ°åˆ†é¡çš„é …ç›®æ•¸: {category_link_count} ç­†")
            print("----------------------------------------------")
            
    except Exception as e:
        print(f"\nâŒ åŒ¯å…¥æª”æ¡ˆã€{category_name}ã€‘éç¨‹ä¸­ç™¼ç”ŸéŒ¯èª¤ (ç¬¬ {i+1} è¡Œ): {e}")
        conn.rollback()
    finally:
        conn.close()


if __name__ == '__main__':
    
    # ğŸš¨ ä¿®æ­£é»ï¼šè™•ç†å¤šå€‹å‘½ä»¤åˆ—åƒæ•¸
    if len(sys.argv) > 1:
        # ç²å–æ‰€æœ‰å¾ sys.argv[1] é–‹å§‹çš„æª”æ¡ˆè·¯å¾‘
        anki_filepaths = sys.argv[1:] 
        
        print(f"\næª¢æ¸¬åˆ° {len(anki_filepaths)} å€‹æª”æ¡ˆï¼Œå°‡ä¾åºåŒ¯å…¥åˆ° {DB_NAME}...")
        
        for filepath in anki_filepaths:
            import_anki_data(filepath)
            
        print("\n==============================================")
        print("ğŸ‰ æ‰€æœ‰æª”æ¡ˆåŒ¯å…¥å®Œæˆï¼")
        print("==============================================")
        
    else:
        # è™•ç†æ²’æœ‰åƒæ•¸æˆ–åªæœ‰ä¸€å€‹åƒæ•¸çš„æƒ…æ³
        print("\n--- Anki æª”æ¡ˆè·¯å¾‘è¨­å®š ---")
        anki_filepath = input(f"è«‹è¼¸å…¥ Anki åŒ¯å‡ºæª”æ¡ˆçš„è·¯å¾‘ï¼ˆä¾‹å¦‚ï¼šC:/Users/.../NEW-JLPT__NEW-N5.txtï¼‰ï¼š")

        print(f"\né–‹å§‹åŒ¯å…¥ Anki æ•¸æ“š ({anki_filepath}) åˆ° {DB_NAME}...")
        import_anki_data(anki_filepath)